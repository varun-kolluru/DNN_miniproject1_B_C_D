{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7f544a-b142-4806-91e5-50fd6b374f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7a59c2-c2d7-4678-ae92-b26dd113d18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 137M/137M [01:17<00:00, 1.78MB/s]\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 1️⃣ Data Preparation\n",
    "# =====================================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),  # <--- Convert grayscale to RGB\n",
    "    transforms.Resize((224, 224)),           # 1️⃣ Resize images\n",
    "    transforms.ToTensor(),                   # 2️⃣ Convert to PyTorch tensor\n",
    "    transforms.Normalize(                    # 3️⃣ Normalize pixel values\n",
    "        mean=[0.485, 0.456, 0.406],          # ImageNet means\n",
    "        std=[0.229, 0.224, 0.225]            # ImageNet std deviations\n",
    "    )\n",
    "])\n",
    "\n",
    "data_dir = \"./data\"\n",
    "dataset = datasets.Caltech101(data_dir, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a120951c-9653-4acb-8d25-11110cf656b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes in dataset: 101\n",
      "class names are : ['Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']\n"
     ]
    }
   ],
   "source": [
    "# Check classes\n",
    "all_classes = dataset.categories  # list of class names (strings)\n",
    "print(\"Total classes in dataset:\", len(all_classes))\n",
    "print(\"class names are :\", all_classes[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c85fcf-f11e-4ae2-bc61-138d2fe5df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 80/20\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a523068-c363-42dc-8bc9-f2628fdbd966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 2️⃣ Define AlexNet Convolutional Layers (Manual)\n",
    "# =====================================================\n",
    "class AlexNetFeatures(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNetFeatures, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        print(\"After layer1 (Conv1):\", x.shape)  # (N, 96, 54, 54)\n",
    "        x = self.layer2(x)\n",
    "        print(\"After layer2 (Conv2):\", x.shape)  # (N, 256, 26, 26)\n",
    "        x = self.layer3(x)\n",
    "        print(\"After layer3 (Conv3):\", x.shape)  # (N, 384, 26, 26)\n",
    "        x = self.layer4(x)\n",
    "        print(\"After layer4 (Conv4):\", x.shape)  # (N, 384, 26, 26)\n",
    "        x = self.layer5(x)\n",
    "        print(\"After layer5 (Conv5):\", x.shape)  # (N, 256, 12, 12)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "423b5c9e-b9fc-4321-8fa8-fa769e7086cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNetFeatures(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate feature extractor\n",
    "alexnet_features = AlexNetFeatures()\n",
    "alexnet_features.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f91984ab-0681-4adf-a8de-7e87d197c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 3️⃣ Extract Features\n",
    "# =====================================================\n",
    "def extract_features(dataloader, model):\n",
    "    features, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "            outputs = model(inputs)\n",
    "            # Pool & flatten\n",
    "            outputs = F.adaptive_avg_pool2d(outputs, (6, 6))\n",
    "            outputs = outputs.view(outputs.size(0), -1)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "    return np.concatenate(features), np.concatenate(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "812ba9e3-aacc-403e-9a04-34ea13b7b89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|                              | 0/217 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|                      | 1/217 [00:00<02:16,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n",
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|▏                     | 2/217 [00:00<01:31,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|▎                     | 3/217 [00:01<01:15,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▍                     | 4/217 [00:01<01:15,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▌                     | 5/217 [00:01<01:08,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   3%|▌                     | 6/217 [00:02<01:05,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   3%|▋                     | 7/217 [00:02<01:02,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▊                     | 8/217 [00:02<00:59,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▉                     | 9/217 [00:02<00:58,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|▉                    | 10/217 [00:03<00:57,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|█                    | 11/217 [00:03<00:56,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|█▏                   | 12/217 [00:03<00:56,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|█▎                   | 13/217 [00:03<00:55,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|█▎                   | 14/217 [00:04<00:55,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|█▍                   | 15/217 [00:04<00:54,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|█▌                   | 16/217 [00:04<00:54,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|█▋                   | 17/217 [00:05<00:54,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|█▋                   | 18/217 [00:05<00:54,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|█▊                   | 19/217 [00:05<00:54,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|█▉                   | 20/217 [00:05<00:53,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|██                   | 21/217 [00:06<00:53,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|██▏                  | 22/217 [00:06<00:52,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|██▏                  | 23/217 [00:06<00:52,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|██▎                  | 24/217 [00:06<00:51,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|██▍                  | 25/217 [00:07<00:51,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|██▌                  | 26/217 [00:07<00:51,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|██▌                  | 27/217 [00:07<00:50,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  13%|██▋                  | 28/217 [00:08<00:50,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  13%|██▊                  | 29/217 [00:08<00:50,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|██▉                  | 30/217 [00:08<00:50,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|███                  | 31/217 [00:08<00:50,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|███                  | 32/217 [00:09<00:49,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|███▏                 | 33/217 [00:09<00:49,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  16%|███▎                 | 34/217 [00:09<00:49,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  16%|███▍                 | 35/217 [00:09<00:48,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|███▍                 | 36/217 [00:10<00:48,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|███▌                 | 37/217 [00:10<00:48,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|███▋                 | 38/217 [00:10<00:51,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|███▊                 | 39/217 [00:11<00:54,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|███▊                 | 40/217 [00:11<00:51,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  19%|███▉                 | 41/217 [00:11<00:50,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  19%|████                 | 42/217 [00:11<00:49,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|████▏                | 43/217 [00:12<00:48,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|████▎                | 44/217 [00:12<00:47,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|████▎                | 45/217 [00:12<00:46,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|████▍                | 46/217 [00:13<00:46,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|████▌                | 47/217 [00:13<00:46,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|████▋                | 48/217 [00:13<00:45,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|████▋                | 49/217 [00:13<00:45,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|████▊                | 50/217 [00:14<00:44,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|████▉                | 51/217 [00:14<00:44,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|█████                | 52/217 [00:14<00:44,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|█████▏               | 53/217 [00:14<00:44,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|█████▏               | 54/217 [00:15<00:43,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|█████▎               | 55/217 [00:15<00:43,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|█████▍               | 56/217 [00:15<00:42,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|█████▌               | 57/217 [00:15<00:42,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|█████▌               | 58/217 [00:16<00:42,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|█████▋               | 59/217 [00:16<00:42,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|█████▊               | 60/217 [00:16<00:42,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|█████▉               | 61/217 [00:17<00:41,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  29%|██████               | 62/217 [00:17<00:41,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  29%|██████               | 63/217 [00:17<00:41,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  29%|██████▏              | 64/217 [00:17<00:40,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██████▎              | 65/217 [00:18<00:41,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██████▍              | 66/217 [00:18<00:41,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|██████▍              | 67/217 [00:18<00:41,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|██████▌              | 68/217 [00:18<00:40,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  32%|██████▋              | 69/217 [00:19<00:40,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  32%|██████▊              | 70/217 [00:19<00:39,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|██████▊              | 71/217 [00:19<00:39,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|██████▉              | 72/217 [00:20<00:38,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███████              | 73/217 [00:20<00:40,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███████▏             | 74/217 [00:20<00:42,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  35%|███████▎             | 75/217 [00:20<00:41,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  35%|███████▎             | 76/217 [00:21<00:39,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  35%|███████▍             | 77/217 [00:21<00:39,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███████▌             | 78/217 [00:21<00:38,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███████▋             | 79/217 [00:21<00:37,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  37%|███████▋             | 80/217 [00:22<00:37,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  37%|███████▊             | 81/217 [00:22<00:36,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███████▉             | 82/217 [00:22<00:36,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|████████             | 83/217 [00:23<00:35,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|████████▏            | 84/217 [00:23<00:35,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|████████▏            | 85/217 [00:23<00:36,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  40%|████████▎            | 86/217 [00:23<00:35,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  40%|████████▍            | 87/217 [00:24<00:35,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████████▌            | 88/217 [00:24<00:35,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████████▌            | 89/217 [00:24<00:34,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████████▋            | 90/217 [00:24<00:34,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████████▊            | 91/217 [00:25<00:34,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████████▉            | 92/217 [00:25<00:33,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  43%|█████████            | 93/217 [00:25<00:33,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  43%|█████████            | 94/217 [00:26<00:33,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|█████████▏           | 95/217 [00:26<00:32,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|█████████▎           | 96/217 [00:26<00:33,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  45%|█████████▍           | 97/217 [00:26<00:35,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  45%|█████████▍           | 98/217 [00:27<00:34,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|█████████▌           | 99/217 [00:27<00:33,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|█████████▏          | 100/217 [00:27<00:32,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|█████████▎          | 101/217 [00:28<00:32,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|█████████▍          | 102/217 [00:28<00:31,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|█████████▍          | 103/217 [00:28<00:31,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  48%|█████████▌          | 104/217 [00:28<00:30,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  48%|█████████▋          | 105/217 [00:29<00:30,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|█████████▊          | 106/217 [00:29<00:29,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|█████████▊          | 107/217 [00:29<00:29,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████████▉          | 108/217 [00:29<00:29,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|██████████          | 109/217 [00:30<00:31,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  51%|██████████▏         | 110/217 [00:30<00:30,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  51%|██████████▏         | 111/217 [00:30<00:29,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|██████████▎         | 112/217 [00:31<00:28,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|██████████▍         | 113/217 [00:31<00:28,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  53%|██████████▌         | 114/217 [00:31<00:28,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  53%|██████████▌         | 115/217 [00:31<00:27,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  53%|██████████▋         | 116/217 [00:32<00:27,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|██████████▊         | 117/217 [00:32<00:27,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|██████████▉         | 118/217 [00:32<00:26,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|██████████▉         | 119/217 [00:32<00:26,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|███████████         | 120/217 [00:33<00:26,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  56%|███████████▏        | 121/217 [00:33<00:26,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  56%|███████████▏        | 122/217 [00:33<00:25,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|███████████▎        | 123/217 [00:34<00:25,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|███████████▍        | 124/217 [00:34<00:24,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|███████████▌        | 125/217 [00:34<00:24,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|███████████▌        | 126/217 [00:34<00:24,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|███████████▋        | 127/217 [00:35<00:24,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|███████████▊        | 128/217 [00:35<00:24,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|███████████▉        | 129/217 [00:35<00:23,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|███████████▉        | 130/217 [00:35<00:23,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|████████████        | 131/217 [00:36<00:23,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  61%|████████████▏       | 132/217 [00:36<00:22,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  61%|████████████▎       | 133/217 [00:36<00:22,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|████████████▎       | 134/217 [00:36<00:22,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|████████████▍       | 135/217 [00:37<00:22,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n",
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|████████████▌       | 136/217 [00:37<00:23,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n",
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|████████████▋       | 137/217 [00:37<00:22,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n",
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  64%|████████████▋       | 138/217 [00:38<00:22,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  64%|████████████▊       | 139/217 [00:38<00:21,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|████████████▉       | 140/217 [00:38<00:21,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|████████████▉       | 141/217 [00:38<00:20,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|█████████████       | 142/217 [00:39<00:20,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|█████████████▏      | 143/217 [00:39<00:19,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|█████████████▎      | 144/217 [00:39<00:19,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  67%|█████████████▎      | 145/217 [00:40<00:19,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  67%|█████████████▍      | 146/217 [00:40<00:19,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|█████████████▌      | 147/217 [00:40<00:18,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|█████████████▋      | 148/217 [00:40<00:18,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  69%|█████████████▋      | 149/217 [00:41<00:18,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  69%|█████████████▊      | 150/217 [00:41<00:18,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|█████████████▉      | 151/217 [00:41<00:17,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████████████      | 152/217 [00:41<00:17,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|██████████████      | 153/217 [00:42<00:17,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|██████████████▏     | 154/217 [00:42<00:16,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|██████████████▎     | 155/217 [00:42<00:17,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  72%|██████████████▍     | 156/217 [00:43<00:18,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  72%|██████████████▍     | 157/217 [00:43<00:17,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|██████████████▌     | 158/217 [00:43<00:16,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|██████████████▋     | 159/217 [00:43<00:16,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|██████████████▋     | 160/217 [00:44<00:15,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|██████████████▊     | 161/217 [00:44<00:15,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  75%|██████████████▉     | 162/217 [00:44<00:14,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  75%|███████████████     | 163/217 [00:44<00:14,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████████████     | 164/217 [00:45<00:14,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████████████▏    | 165/217 [00:45<00:13,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████████████▎    | 166/217 [00:45<00:13,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  77%|███████████████▍    | 167/217 [00:46<00:13,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  77%|███████████████▍    | 168/217 [00:46<00:13,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████████████▌    | 169/217 [00:46<00:13,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████████████▋    | 170/217 [00:46<00:12,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████████████▊    | 171/217 [00:47<00:12,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████████████▊    | 172/217 [00:47<00:12,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  80%|███████████████▉    | 173/217 [00:47<00:11,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  80%|████████████████    | 174/217 [00:47<00:11,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████████████▏   | 175/217 [00:48<00:11,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████████████▏   | 176/217 [00:48<00:10,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████████████▎   | 177/217 [00:48<00:10,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████████████▍   | 178/217 [00:49<00:10,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████████████▍   | 179/217 [00:49<00:10,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  83%|████████████████▌   | 180/217 [00:49<00:09,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  83%|████████████████▋   | 181/217 [00:49<00:09,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████████████▊   | 182/217 [00:50<00:09,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████████████▊   | 183/217 [00:50<00:09,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  85%|████████████████▉   | 184/217 [00:50<00:08,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  85%|█████████████████   | 185/217 [00:50<00:08,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|█████████████████▏  | 186/217 [00:51<00:08,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|█████████████████▏  | 187/217 [00:51<00:08,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|█████████████████▎  | 188/217 [00:51<00:07,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|█████████████████▍  | 189/217 [00:51<00:07,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  88%|█████████████████▌  | 190/217 [00:52<00:07,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  88%|█████████████████▌  | 191/217 [00:52<00:06,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  88%|█████████████████▋  | 192/217 [00:52<00:06,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|█████████████████▊  | 193/217 [00:53<00:06,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n",
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|█████████████████▉  | 194/217 [00:53<00:06,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n",
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████████████▉  | 195/217 [00:53<00:06,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|██████████████████  | 196/217 [00:53<00:05,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  91%|██████████████████▏ | 197/217 [00:54<00:05,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  91%|██████████████████▏ | 198/217 [00:54<00:05,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|██████████████████▎ | 199/217 [00:54<00:04,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|██████████████████▍ | 200/217 [00:55<00:04,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  93%|██████████████████▌ | 201/217 [00:55<00:04,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  93%|██████████████████▌ | 202/217 [00:55<00:04,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|██████████████████▋ | 203/217 [00:55<00:03,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|██████████████████▊ | 204/217 [00:56<00:03,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|██████████████████▉ | 205/217 [00:56<00:03,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|██████████████████▉ | 206/217 [00:56<00:02,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|███████████████████ | 207/217 [00:56<00:02,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  96%|███████████████████▏| 208/217 [00:57<00:02,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  96%|███████████████████▎| 209/217 [00:57<00:02,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|███████████████████▎| 210/217 [00:57<00:01,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|███████████████████▍| 211/217 [00:57<00:01,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|███████████████████▌| 212/217 [00:58<00:01,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|███████████████████▋| 213/217 [00:58<00:01,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  99%|███████████████████▋| 214/217 [00:58<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  99%|███████████████████▊| 215/217 [00:59<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|███████████████████▉| 216/217 [00:59<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|████████████████████| 217/217 [00:59<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([29, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([29, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([29, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([29, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([29, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting features:   2%|▍                      | 1/55 [00:00<00:17,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▊                      | 2/55 [00:00<00:15,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|█▎                     | 3/55 [00:00<00:14,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|█▋                     | 4/55 [00:01<00:14,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|██                     | 5/55 [00:01<00:14,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|██▌                    | 6/55 [00:01<00:13,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  13%|██▉                    | 7/55 [00:02<00:13,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|███▎                   | 8/55 [00:02<00:13,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  16%|███▊                   | 9/55 [00:02<00:13,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|████                  | 10/55 [00:02<00:12,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|████▍                 | 11/55 [00:03<00:12,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|████▊                 | 12/55 [00:03<00:12,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|█████▏                | 13/55 [00:03<00:11,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|█████▌                | 14/55 [00:03<00:11,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██████                | 15/55 [00:04<00:11,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  29%|██████▍               | 16/55 [00:04<00:11,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|██████▊               | 17/55 [00:04<00:10,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███████▏              | 18/55 [00:05<00:10,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  35%|███████▌              | 19/55 [00:05<00:10,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|████████              | 20/55 [00:05<00:09,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|████████▍             | 21/55 [00:05<00:09,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  40%|████████▊             | 22/55 [00:06<00:09,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|█████████▏            | 23/55 [00:06<00:08,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|█████████▌            | 24/55 [00:06<00:08,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  45%|██████████            | 25/55 [00:07<00:08,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|██████████▍           | 26/55 [00:07<00:07,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|██████████▊           | 27/55 [00:07<00:07,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  51%|███████████▏          | 28/55 [00:07<00:07,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  53%|███████████▌          | 29/55 [00:08<00:07,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|████████████          | 30/55 [00:08<00:06,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  56%|████████████▍         | 31/55 [00:08<00:06,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|████████████▊         | 32/55 [00:08<00:06,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|█████████████▏        | 33/55 [00:09<00:06,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|█████████████▌        | 34/55 [00:09<00:05,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  64%|██████████████        | 35/55 [00:09<00:05,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████████████▍       | 36/55 [00:10<00:05,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  67%|██████████████▊       | 37/55 [00:10<00:04,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  69%|███████████████▏      | 38/55 [00:10<00:04,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████████████▌      | 39/55 [00:10<00:04,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|████████████████      | 40/55 [00:11<00:04,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  75%|████████████████▍     | 41/55 [00:11<00:03,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|████████████████▊     | 42/55 [00:11<00:03,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|█████████████████▏    | 43/55 [00:11<00:03,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  80%|█████████████████▌    | 44/55 [00:12<00:03,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|██████████████████    | 45/55 [00:12<00:02,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|██████████████████▍   | 46/55 [00:12<00:02,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  85%|██████████████████▊   | 47/55 [00:13<00:02,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|███████████████████▏  | 48/55 [00:13<00:01,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|███████████████████▌  | 49/55 [00:13<00:01,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  91%|████████████████████  | 50/55 [00:13<00:01,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  93%|████████████████████▍ | 51/55 [00:14<00:01,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|████████████████████▊ | 52/55 [00:14<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  96%|█████████████████████▏| 53/55 [00:14<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████████████████▌| 54/55 [00:15<00:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([32, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([32, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([32, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([32, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([32, 256, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████████████████| 55/55 [00:15<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer1 (Conv1): torch.Size([8, 96, 27, 27])\n",
      "After layer2 (Conv2): torch.Size([8, 256, 13, 13])\n",
      "After layer3 (Conv3): torch.Size([8, 384, 13, 13])\n",
      "After layer4 (Conv4): torch.Size([8, 384, 13, 13])\n",
      "After layer5 (Conv5): torch.Size([8, 256, 6, 6])\n",
      "Train features: (6941, 9216)\n",
      "Test features: (1736, 9216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = extract_features(train_loader, alexnet_features)\n",
    "X_test, y_test = extract_features(test_loader, alexnet_features)\n",
    "\n",
    "print(\"Train features:\", X_train.shape)\n",
    "print(\"Test features:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e749afc-f3d9-4c34-b394-437b77b948d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 4️⃣ Standardize Features\n",
    "# =====================================================\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83b4b196-d5d6-48d1-82e0-eba871f0eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 5️⃣ Train and Evaluate Multiple ML Models\n",
    "# =====================================================\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51ae8d49-e3e6-40c3-81e3-483bdb20e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faca137b-6fde-4d6c-afe2-37f0797a90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ffee30f-0011-4a34-8549-080d7f623315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ OUTPUT SHAPES & ACCURACIES ================\n",
      "Logistic Regression Accuracy : 65.03%\n",
      "Random Forest Accuracy       : 45.68%\n",
      "SVM Accuracy (linear)        : 61.81%\n",
      "\n",
      "Detailed Classification Report (LR):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92        90\n",
      "           1       0.96      0.96      0.96       110\n",
      "           2       0.79      0.89      0.84        38\n",
      "           3       0.95      1.00      0.98       177\n",
      "           4       1.00      0.57      0.73         7\n",
      "           5       0.92      0.95      0.94       162\n",
      "           6       0.25      0.11      0.15         9\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00        14\n",
      "           9       0.00      0.00      0.00        12\n",
      "          10       0.50      0.33      0.40         9\n",
      "          11       0.75      0.33      0.46         9\n",
      "          12       0.50      0.67      0.57        21\n",
      "          13       0.63      0.71      0.67        24\n",
      "          14       0.15      0.33      0.21         6\n",
      "          15       0.25      0.36      0.30        11\n",
      "          16       0.45      0.38      0.42        13\n",
      "          17       1.00      0.50      0.67         8\n",
      "          18       0.17      0.08      0.11        13\n",
      "          19       0.77      0.95      0.85        21\n",
      "          20       0.33      0.08      0.12        13\n",
      "          21       0.62      1.00      0.76         8\n",
      "          22       0.25      0.10      0.14        10\n",
      "          23       0.62      0.62      0.62        21\n",
      "          24       0.33      0.29      0.31         7\n",
      "          25       0.35      0.35      0.35        17\n",
      "          26       0.20      0.13      0.16        15\n",
      "          27       0.56      0.31      0.40        16\n",
      "          28       0.00      0.00      0.00         4\n",
      "          29       0.25      0.11      0.15         9\n",
      "          30       0.29      0.17      0.21        12\n",
      "          31       0.42      0.56      0.48         9\n",
      "          32       0.73      0.73      0.73        11\n",
      "          33       0.30      0.20      0.24        15\n",
      "          34       0.64      0.64      0.64        14\n",
      "          35       0.43      0.60      0.50        10\n",
      "          36       0.36      0.36      0.36        11\n",
      "          37       0.25      0.18      0.21        11\n",
      "          38       0.62      0.38      0.48        13\n",
      "          39       0.45      0.31      0.37        16\n",
      "          40       0.33      0.42      0.37        12\n",
      "          41       0.45      0.38      0.42        13\n",
      "          42       0.42      0.45      0.43        11\n",
      "          43       1.00      0.60      0.75         5\n",
      "          44       0.00      0.00      0.00         4\n",
      "          45       1.00      0.60      0.75        10\n",
      "          46       0.85      0.77      0.81        22\n",
      "          47       0.74      0.74      0.74        27\n",
      "          48       1.00      0.71      0.83         7\n",
      "          49       0.33      0.30      0.32        10\n",
      "          50       0.26      0.42      0.32        12\n",
      "          51       0.47      0.41      0.44        17\n",
      "          52       0.17      0.33      0.22         3\n",
      "          53       0.57      0.67      0.62        12\n",
      "          54       0.32      0.50      0.39        12\n",
      "          55       0.53      0.68      0.60        25\n",
      "          56       0.36      0.56      0.43         9\n",
      "          57       0.60      0.56      0.58        16\n",
      "          58       0.36      0.28      0.31        18\n",
      "          59       0.38      0.30      0.33        10\n",
      "          60       0.56      0.53      0.55        17\n",
      "          61       0.67      0.80      0.73         5\n",
      "          62       0.57      0.50      0.53         8\n",
      "          63       0.53      0.62      0.57        16\n",
      "          64       0.75      0.43      0.55         7\n",
      "          65       0.79      0.85      0.81        13\n",
      "          66       0.40      0.27      0.32        15\n",
      "          67       0.75      0.33      0.46         9\n",
      "          68       0.54      0.88      0.67         8\n",
      "          69       1.00      0.80      0.89         5\n",
      "          70       0.62      0.56      0.59         9\n",
      "          71       0.57      0.36      0.44        11\n",
      "          72       0.27      0.38      0.32         8\n",
      "          73       0.40      0.29      0.33         7\n",
      "          74       0.19      0.21      0.20        14\n",
      "          75       0.53      0.62      0.57        13\n",
      "          76       0.32      0.46      0.38        13\n",
      "          77       0.44      0.57      0.50         7\n",
      "          78       0.40      0.50      0.44        12\n",
      "          79       0.40      0.29      0.33        14\n",
      "          80       0.20      0.33      0.25         3\n",
      "          81       0.50      0.85      0.63        13\n",
      "          82       0.08      0.08      0.08        12\n",
      "          83       0.57      0.67      0.62         6\n",
      "          84       0.64      0.64      0.64        11\n",
      "          85       0.36      0.50      0.42        10\n",
      "          86       0.53      0.44      0.48        18\n",
      "          87       0.40      0.36      0.38        11\n",
      "          88       0.79      0.79      0.79        14\n",
      "          89       0.50      0.50      0.50         2\n",
      "          90       0.63      1.00      0.77        12\n",
      "          91       0.60      0.60      0.60        10\n",
      "          92       0.82      1.00      0.90        18\n",
      "          93       0.67      0.38      0.48        21\n",
      "          94       0.75      0.78      0.77        51\n",
      "          95       0.40      0.33      0.36         6\n",
      "          96       0.50      0.27      0.35        11\n",
      "          97       0.00      0.00      0.00         7\n",
      "          98       1.00      0.67      0.80        15\n",
      "          99       0.22      0.33      0.27         6\n",
      "         100       0.62      0.77      0.69        13\n",
      "\n",
      "    accuracy                           0.65      1736\n",
      "   macro avg       0.50      0.48      0.48      1736\n",
      "weighted avg       0.65      0.65      0.64      1736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 6️⃣ Report Results\n",
    "# =====================================================\n",
    "print(\"\\n================ OUTPUT SHAPES & ACCURACIES ================\")\n",
    "print(f\"Logistic Regression Accuracy : {acc_lr*100:.2f}%\")\n",
    "print(f\"Random Forest Accuracy       : {acc_rf*100:.2f}%\")\n",
    "print(f\"SVM Accuracy (linear)        : {acc_svm*100:.2f}%\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report (LR):\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e821e1-2b51-412b-ba20-fcfad1bbe9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
